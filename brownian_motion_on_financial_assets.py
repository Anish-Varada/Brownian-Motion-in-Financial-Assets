# -*- coding: utf-8 -*-
"""Brownian motion on Financial Assets

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UqsRB8Tkj2cZCRtrjnL0TAj9wDC4bq5q
"""

import numpy as np
import yfinance as yf
from scipy.stats import linregress, kstest
import matplotlib.pyplot as plt
import fbm
import warnings
import pandas as pd

warnings.filterwarnings('ignore')
DT = 1.0 / 252
taus = np.arange(1, 30)
np.random.seed(42)

def analyze_stock(config):
    t, t_start, t_end, test_start, test_end = config['ticker'], config['train_start'], config['train_end'], config['test_start'], config['test_end']
    print(f"\n{'='*80}\n--- Analyzing {t} ---\nTrain: {t_start} to {t_end} | Test: {test_start} to {test_end}\n{'='*80}")
    data = yf.download(t, start=t_start, end=test_end, auto_adjust=True, progress=False, threads=False)

    if data.empty:
        print(f"Error: No data fetched for {t}. Check dates.")
        return

    prices = data['Close'][t] if isinstance(data.columns, pd.MultiIndex) else data['Close']
    prices = prices.dropna()

    train = prices.loc[t_start:t_end]
    test = prices.loc[test_start:test_end]

    if len(train) < 30 or len(test) < 5:
        print(f"Error: Insufficient data for {t}. Train: {len(train)}, Test: {len(test)}")
        return

    tr_log = np.log(train / train.shift(1)).dropna()
    te_log = np.log(test / test.shift(1)).dropna()

    tr_diff = train.diff(1).dropna()
    te_diff = test.diff(1).dropna()

    train_vol = tr_log.std(ddof=1) * np.sqrt(252)
    test_vol = te_log.std(ddof=1) * np.sqrt(252)
    print(f"Training Volatility (Annualized): {train_vol:.4f}")
    print(f"Testing Volatility (Annualized):  {test_vol:.4f}")

    # --- 1. GBM Estimation ---
    gbm_mu = (tr_log.mean() / DT) + (tr_log.var(ddof=1) / DT) / 2
    gbm_sigma = np.sqrt(tr_log.var(ddof=1) / DT)

    # --- 2. GfBM Estimation (Log-Return Scaling) ---
    vars_gfbm, valid_gfbm = [], []
    gfbm_slope, gfbm_intercept = 0, 0
    for tau in taus:
        s = np.log(train / train.shift(tau)).dropna()
        if len(s) > 10 and (v := s.var(ddof=1)) > 0:
            vars_gfbm.append(np.log(v)); valid_gfbm.append(tau)

    if len(valid_gfbm) > 2:
        gfbm_slope, gfbm_intercept, _, _, _ = linregress(np.log(np.array(valid_gfbm) * DT), vars_gfbm)
        gfbm_H, gfbm_sigma = gfbm_slope / 2, np.sqrt(np.exp(gfbm_intercept))
    else:
        gfbm_H, gfbm_sigma = 0.5, gbm_sigma
    gfbm_mu = gbm_mu

    # --- 3. fBM Estimation (Price Diff Scaling) ---
    vars_fbm, valid_fbm = [], []
    fbm_slope, fbm_intercept = 0, 0
    for tau in taus:
        s = train.diff(tau).dropna()
        if len(s) > 10 and (v := s.var(ddof=1)) > 0:
            vars_fbm.append(np.log(v)); valid_fbm.append(tau)

    if len(valid_fbm) > 2:
        fbm_slope, fbm_intercept, _, _, _ = linregress(np.log(np.array(valid_fbm) * DT), vars_fbm)
        fbm_H = fbm_slope / 2
        fbm_sigma = np.sqrt(np.exp(fbm_intercept))
        fbm_mean_diff = tr_diff.mean()
    else:
        fbm_H, fbm_sigma, fbm_mean_diff = 0.5, gbm_sigma, tr_diff.mean()

    # --- Report Parameters ---
    print(f"GBM:  nu={gbm_mu:.4f}, sigma={gbm_sigma:.4f}")
    print(f"fBM:  sigma={fbm_sigma:.4f}, Hurst={fbm_H:.4f}")
    print(f"GfBM: nu={gfbm_mu:.4f}, sigma={gfbm_sigma:.4f}, Hurst={gfbm_H:.4f}")

    # --- KS Tests ---
    # GBM
    z_gbm = (te_log - (gbm_mu - 0.5 * gbm_sigma**2) * DT) / (gbm_sigma * np.sqrt(DT))
    p_gbm = kstest(z_gbm, 'norm').pvalue

    # GfBM
    z_gfbm = (te_log - (gbm_mu - 0.5 * gfbm_sigma**2) * DT) / (gfbm_sigma * (DT ** gfbm_H))
    p_gfbm = kstest(z_gfbm, 'norm').pvalue

    # fBM
    denom = fbm_sigma * (DT ** fbm_H)
    p_fbm = kstest((te_diff - fbm_mean_diff) / denom, 'norm').pvalue if denom > 0 else 0.0

    print(f"P-Values -> GBM: {p_gbm:.6f} | GfBM: {p_gfbm:.6f} | fBM: {p_fbm:.6f}")

    winner_key = max({'GBM': p_gbm, 'GfBM': p_gfbm, 'fBM': p_fbm}, key=lambda k: {'GBM': p_gbm, 'GfBM': p_gfbm, 'fBM': p_fbm}[k])
    print(f"Winner: {winner_key}")

    print(f"Displaying and Saving figures for {t}...")

    # Prep for Fan Charts
    n, S0 = len(test) - 1, test.iloc[0]
    t_vec = np.linspace(0, n * DT, n + 1)

    # 3. GBM Fan Chart
    plt.figure(figsize=(10, 6))
    plt.plot(test.index, test.values, 'k', lw=2, label='Actual', zorder=10)
    for _ in range(30):
        b = np.concatenate(([0], np.cumsum(np.random.normal(0, 1, n) * np.sqrt(DT))))
        path = S0 * np.exp((gbm_mu - 0.5*gbm_sigma**2)*t_vec + gbm_sigma*b)
        plt.plot(test.index, path, 'skyblue', alpha=0.3)
    plt.title(f'{t} GBM Simulation (p={p_gbm:.4f})'); plt.grid(True); plt.legend(['Actual', 'GBM Sim'])
    plt.savefig(f'{t}_GBM_FanChart.png')
    plt.show()

    # 4. GfBM Fan Chart
    plt.figure(figsize=(10, 6))
    plt.plot(test.index, test.values, 'k', lw=2, label='Actual', zorder=10)
    for _ in range(30):
        fgn = fbm.FBM(n=n, hurst=gfbm_H, length=n*DT, method='daviesharte').fbm()
        path = S0 * np.exp((gfbm_mu - 0.5*gfbm_sigma**2)*t_vec + gfbm_sigma*fgn)
        plt.plot(test.index, path, 'lightcoral', alpha=0.3)
    plt.title(f'{t} GfBM Simulation (p={p_gfbm:.4f})'); plt.grid(True); plt.legend(['Actual', 'GfBM Sim'])
    plt.savefig(f'{t}_GfBM_FanChart.png')
    plt.show()

    # 5. fBM Fan Chart (Arithmetic)
    plt.figure(figsize=(10, 6))
    plt.plot(test.index, test.values, 'k', lw=2, label='Actual', zorder=10)
    for _ in range(30):
        bh = fbm.FBM(n=n, hurst=fbm_H, length=n*DT, method='daviesharte').fbm()
        drift_vec = np.arange(n + 1) * fbm_mean_diff
        path = S0 + drift_vec + fbm_sigma * bh
        plt.plot(test.index, path, 'lightgreen', alpha=0.3)
    plt.title(f'{t} fBM Simulation (p={p_fbm:.4f})'); plt.grid(True); plt.legend(['Actual', 'fBM Sim'])
    plt.savefig(f'{t}_FBM_FanChart.png')
    plt.show()

configs = [
    {'ticker': 'TSLA', 'train_start': '2010-06-29', 'train_end': '2019-12-31', 'test_start': '2020-01-01', 'test_end': '2024-12-31'},
    {'ticker': 'ED',  'train_start': '2018-01-01', 'train_end': '2022-12-31', 'test_start': '2023-01-01', 'test_end': '2023-12-31'},
    {'ticker': 'SHW', 'train_start': '2016-01-01', 'train_end': '2018-12-31', 'test_start': '2019-01-01', 'test_end': '2019-12-31'}
]

for c in configs: analyze_stock(c)